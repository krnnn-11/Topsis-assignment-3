# -*- coding: utf-8 -*-
"""Untitled4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DcT_34alxnf5rTRKvrwoeceX3Fqukp0A
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Step 1: Define the models and criteria
models = ['GPT-4', 'LLaMA 2', 'Claude', 'Mistral', 'PaLM 2']
criteria = ['PPL', 'RC', 'FLU', 'LAT', 'FA']  # PPL & LAT are cost criteria, others are benefit

# Decision Matrix (Rows: Models, Columns: Criteria)
data = np.array([
    [10, 0.9, 0.95, 300, 0.92],
    [15, 0.85, 0.90, 280, 0.88],
    [12, 0.87, 0.93, 320, 0.90],
    [14, 0.86, 0.91, 260, 0.85],
    [11, 0.88, 0.92, 310, 0.89]
])

# Step 2: Define benefit (+) and cost (-) criteria
weights = np.array([0.25, 0.20, 0.20, 0.15, 0.20])  # Weights for criteria
criteria_type = np.array([-1, 1, 1, -1, 1])  # -1 for cost, 1 for benefit

# Step 3: Normalize the decision matrix
norm_matrix = data / np.sqrt((data ** 2).sum(axis=0))

# Step 4: Weight the normalized decision matrix
weighted_matrix = norm_matrix * weights

# Step 5: Determine the ideal best and worst
ideal_best = np.where(criteria_type == 1, weighted_matrix.max(axis=0), weighted_matrix.min(axis=0))
ideal_worst = np.where(criteria_type == 1, weighted_matrix.min(axis=0), weighted_matrix.max(axis=0))

# Step 6: Calculate separation measures
distance_best = np.sqrt(((weighted_matrix - ideal_best) ** 2).sum(axis=1))
distance_worst = np.sqrt(((weighted_matrix - ideal_worst) ** 2).sum(axis=1))

# Step 7: Calculate relative closeness to the ideal solution
scores = distance_worst / (distance_best + distance_worst)

# Step 8: Rank models
rankings = np.argsort(scores)[::-1] + 1

# Create a results dataframe
results = pd.DataFrame({'Model': models, 'TOPSIS Score': scores, 'Rank': rankings})
results = results.sort_values(by='Rank')

# Plot the results
plt.figure(figsize=(10, 5))
sns.barplot(x=results['Model'], y=results['TOPSIS Score'], palette='viridis', order=results['Model'])
plt.xlabel('Models')
plt.ylabel('TOPSIS Score')
plt.title('TOPSIS Score of Pre-Trained Models')
plt.xticks(rotation=45)
plt.show()

# Display the results table
print(results)